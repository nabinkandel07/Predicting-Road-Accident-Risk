{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec3b087f",
   "metadata": {
    "papermill": {
     "duration": 0.003371,
     "end_time": "2025-11-02T06:04:45.811442",
     "exception": false,
     "start_time": "2025-11-02T06:04:45.808071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Predicting Road Accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b335c",
   "metadata": {
    "papermill": {
     "duration": 0.002669,
     "end_time": "2025-11-02T06:04:45.817289",
     "exception": false,
     "start_time": "2025-11-02T06:04:45.814620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction \n",
    "\n",
    "Predicting the likelihood of road accidents is a crucial challenge in improving urban safety and optimizing traffic management systems. In this notebook, we aim to model and predict road accident risk based on structured features provided in the dataset.\n",
    "\n",
    "The workflow follows a clean, modular, and reproducible data science pipeline:\n",
    "\n",
    "1. Data Loading & Exploration: We begin by detecting and loading the competition dataset (train.csv, test.csv) dynamically from the Kaggle input directory.\n",
    "\n",
    "2. Preprocessing & Encoding: Categorical features are encoded using OrdinalEncoder for efficient use in tree-based models.\n",
    "\n",
    "3. Modeling & Cross-Validation: Two strong baseline regressors are employed — HistGradientBoostingRegressor and RandomForestRegressor — both robust to non-linear relationships and capable of handling mixed-type data.A 5-Fold cross-validation setup ensures stable model evaluation and mitigates overfitting risk.\n",
    "\n",
    "5. Evaluation & Results: Model performance is assessed using Mean Absolute Error (MAE), providing an interpretable measure of prediction accuracy.\n",
    "\n",
    "This notebook emphasizes clarity, performance reproducibility, and interpretable results — serving as a strong baseline for further feature engineering and model optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c61ebbb",
   "metadata": {
    "papermill": {
     "duration": 0.002392,
     "end_time": "2025-11-02T06:04:45.822201",
     "exception": false,
     "start_time": "2025-11-02T06:04:45.819809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9c6c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T06:04:45.828525Z",
     "iopub.status.busy": "2025-11-02T06:04:45.828082Z",
     "iopub.status.idle": "2025-11-02T06:04:49.138566Z",
     "shell.execute_reply": "2025-11-02T06:04:49.137932Z"
    },
    "papermill": {
     "duration": 3.315193,
     "end_time": "2025-11-02T06:04:49.139952",
     "exception": false,
     "start_time": "2025-11-02T06:04:45.824759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ========= Imports =========\n",
    "import os, glob, gc, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "# Basic models from sklearn (fast to run)\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# Encoders + preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# ========= CONFIG =========\n",
    "TARGET_COL = \"accident_risk\"\n",
    "ID_COL     = \"id\"\n",
    "N_SPLITS   = 5      # K-Fold splits\n",
    "RANDOM_SEED = 42\n",
    "VERBOSE = True\n",
    "PREFERRED_DIR_NAME = \"predict\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a5964f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T06:04:49.146987Z",
     "iopub.status.busy": "2025-11-02T06:04:49.146642Z",
     "iopub.status.idle": "2025-11-02T06:04:50.875195Z",
     "shell.execute_reply": "2025-11-02T06:04:50.874171Z"
    },
    "papermill": {
     "duration": 1.733689,
     "end_time": "2025-11-02T06:04:50.876573",
     "exception": false,
     "start_time": "2025-11-02T06:04:49.142884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found competition dir: /kaggle/input/playground-series-s5e10\n",
      "Train shape: (517754, 14)\n",
      "Test shape : (172585, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========= Data Loading =========\n",
    "\n",
    "def find_kaggle_comp_dir():\n",
    "    base = '/kaggle/input'\n",
    "    if not os.path.exists(base):\n",
    "        return None\n",
    "    candidates = []\n",
    "    for d in glob.glob(os.path.join(base, '*')):\n",
    "        if os.path.isdir(d):\n",
    "            has_train = len(glob.glob(os.path.join(d, 'train.csv'))) > 0\n",
    "            has_test  = len(glob.glob(os.path.join(d, 'test.csv'))) > 0\n",
    "            if has_train and has_test:\n",
    "                candidates.append(d)\n",
    "    if candidates:\n",
    "        cand_pref = [d for d in candidates if PREFERRED_DIR_NAME.lower() in os.path.basename(d).lower()]\n",
    "        return cand_pref[0] if cand_pref else candidates[0]\n",
    "    return None\n",
    "\n",
    "comp_dir = find_kaggle_comp_dir()\n",
    "\n",
    "if comp_dir is not None:\n",
    "    if VERBOSE: print(f\"Found competition dir: {comp_dir}\")\n",
    "    train_path = os.path.join(comp_dir, 'train.csv')\n",
    "    test_path  = os.path.join(comp_dir, 'test.csv')\n",
    "    train = pd.read_csv(train_path)\n",
    "    test  = pd.read_csv(test_path)\n",
    "else:\n",
    "    if VERBOSE: print(\"Competition files not found. Using a small synthetic dataset so the notebook can run.\")\n",
    "    rng = np.random.RandomState(RANDOM_SEED)\n",
    "    n_train, n_test = 1200, 800\n",
    "    dates = pd.date_range('2021-01-01', periods=n_train+n_test, freq='H')\n",
    "    cat1  = rng.choice(['A','B','C'], size=n_train+n_test)\n",
    "    cat2  = rng.choice(['Urban','Rural'], size=n_train+n_test)\n",
    "    num1  = rng.normal(0,1,size=n_train+n_test)\n",
    "    num2  = rng.gamma(2.0,1.0,size=n_train+n_test)\n",
    "    # target with some signal\n",
    "    target = 0.3*(cat1=='B').astype(float) + 0.6*(cat2=='Urban').astype(float) + 0.5*num1 + 0.2*np.log1p(num2) + rng.normal(0,0.3,size=n_train+n_test)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'id': np.arange(n_train+n_test),\n",
    "        'timestamp': dates.astype(str),\n",
    "        'weather_cat': cat1,\n",
    "        'area_cat': cat2,\n",
    "        'speed_mean': num1,\n",
    "        'traffic_index': num2,\n",
    "        'target': target\n",
    "    })\n",
    "    train = df.iloc[:n_train].copy()\n",
    "    test  = df.iloc[n_train:].drop(columns=['target']).copy()\n",
    "\n",
    "# show shapes\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape :\", test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a56348",
   "metadata": {
    "papermill": {
     "duration": 0.003098,
     "end_time": "2025-11-02T06:04:50.884674",
     "exception": false,
     "start_time": "2025-11-02T06:04:50.881576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Preprocessing & Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "846c5d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T06:04:50.890999Z",
     "iopub.status.busy": "2025-11-02T06:04:50.890755Z",
     "iopub.status.idle": "2025-11-02T06:04:51.843306Z",
     "shell.execute_reply": "2025-11-02T06:04:51.842312Z"
    },
    "papermill": {
     "duration": 0.957182,
     "end_time": "2025-11-02T06:04:51.844650",
     "exception": false,
     "start_time": "2025-11-02T06:04:50.887468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET_COL: accident_risk\n",
      "ID_COL    : id\n",
      "Using 13 features.\n"
     ]
    }
   ],
   "source": [
    "# ========= Column Detection =========\n",
    "if TARGET_COL is None:\n",
    "    only_in_train = [c for c in train.columns if c not in test.columns]\n",
    "    # don't treat typical meta columns as target\n",
    "    bad_target_names = set(['fold', 'kfold', 'split', 'subset'])\n",
    "    candidates = [c for c in only_in_train if c.lower() not in bad_target_names]\n",
    "    if len(candidates) == 0:\n",
    "        TARGET_COL = train.columns[-1]\n",
    "    else:\n",
    "        TARGET_COL = candidates[0]\n",
    "\n",
    "if ID_COL is None:\n",
    "    for guess in ['id','ID','Id','record_id']:\n",
    "        if guess in test.columns:\n",
    "            ID_COL = guess\n",
    "            break\n",
    "    if ID_COL is None:\n",
    "        both = [c for c in train.columns if c in test.columns]\n",
    "        id_like = None\n",
    "        for c in both:\n",
    "            # quick check: many unique values & no missing\n",
    "            if train[c].isna().sum() == 0 and train[c].nunique() > 0.9*len(train):\n",
    "                id_like = c\n",
    "                break\n",
    "        ID_COL = id_like if id_like is not None else both[0]\n",
    "\n",
    "print(\"TARGET_COL:\", TARGET_COL)\n",
    "print(\"ID_COL    :\", ID_COL)\n",
    "\n",
    "# ========= Basic date parsing =========\n",
    "def enrich_dates(df):\n",
    "    for c in list(df.columns):\n",
    "        if df[c].dtype == 'object':\n",
    "            sample = df[c].dropna().astype(str).head(50)\n",
    "            parse_ok = 0\n",
    "            for x in sample:\n",
    "                try:\n",
    "                    _ = pd.to_datetime(x, errors='raise')\n",
    "                    parse_ok += 1\n",
    "                except:\n",
    "                    pass\n",
    "            if parse_ok > 0.8*len(sample) and len(sample)>0:\n",
    "                # convert\n",
    "                dt = pd.to_datetime(df[c], errors='coerce')\n",
    "                df[c+'_year'] = dt.dt.year\n",
    "                df[c+'_month'] = dt.dt.month\n",
    "                df[c+'_day'] = dt.dt.day\n",
    "                df[c+'_hour'] = dt.dt.hour\n",
    "                # drop original text col (keeps it simple)\n",
    "                df.drop(columns=[c], inplace=True)\n",
    "    return df\n",
    "\n",
    "train = enrich_dates(train)\n",
    "test  = enrich_dates(test)\n",
    "\n",
    "# ========= Identify numeric / categorical =========\n",
    "# Simple rule: object and 'category' dtypes treated as categorical.\n",
    "cat_cols = [c for c in train.columns if train[c].dtype == 'object' or str(train[c].dtype)=='category']\n",
    "num_cols = [c for c in train.columns if c not in cat_cols+[TARGET_COL]]\n",
    "\n",
    "# ========= Fill missing =========\n",
    "# For numeric, we fill with median. For categorical, we fill with \"missing\".\n",
    "for c in num_cols:\n",
    "    if train[c].isna().any():\n",
    "        med = train[c].median()\n",
    "        train[c] = train[c].fillna(med)\n",
    "        test[c]  = test[c].fillna(med)\n",
    "\n",
    "for c in cat_cols:\n",
    "    train[c] = train[c].fillna(\"missing\")\n",
    "    test[c]  = test[c].fillna(\"missing\")\n",
    "\n",
    "# ========= Encode categoricals with a simple OrdinalEncoder =========\n",
    "if len(cat_cols) > 0:\n",
    "    enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    train[cat_cols] = enc.fit_transform(train[cat_cols])\n",
    "    test[cat_cols]  = enc.transform(test[cat_cols])\n",
    "\n",
    "# final feature list (exclude target)\n",
    "features = [c for c in train.columns if c != TARGET_COL]\n",
    "print(f\"Using {len(features)} features.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89045943",
   "metadata": {
    "papermill": {
     "duration": 0.002512,
     "end_time": "2025-11-02T06:04:51.850367",
     "exception": false,
     "start_time": "2025-11-02T06:04:51.847855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Modeling & Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9232902c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T06:04:51.856643Z",
     "iopub.status.busy": "2025-11-02T06:04:51.856429Z",
     "iopub.status.idle": "2025-11-02T06:24:08.917432Z",
     "shell.execute_reply": "2025-11-02T06:24:08.916621Z"
    },
    "papermill": {
     "duration": 1157.068864,
     "end_time": "2025-11-02T06:24:08.921828",
     "exception": false,
     "start_time": "2025-11-02T06:04:51.852964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M1] Fold 0 MAE = 0.043760\n",
      "[M2] Fold 0 MAE = 0.044870\n",
      "[M1] Fold 1 MAE = 0.043697\n",
      "[M2] Fold 1 MAE = 0.044850\n",
      "[M1] Fold 2 MAE = 0.043831\n",
      "[M2] Fold 2 MAE = 0.045080\n",
      "[M1] Fold 3 MAE = 0.043529\n",
      "[M2] Fold 3 MAE = 0.044678\n",
      "[M1] Fold 4 MAE = 0.043660\n",
      "[M2] Fold 4 MAE = 0.044810\n",
      "\n",
      "Summary:\n",
      " Model 1 CV mae: 0.043695 ± 0.000101\n",
      " Model 2 CV mae: 0.044858 ± 0.000130\n"
     ]
    }
   ],
   "source": [
    "# ========= CV Training =========\n",
    "X = train[features].copy()\n",
    "y = train[TARGET_COL].values\n",
    "X_test = test[features].copy()\n",
    "\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "oof_m1 = np.zeros(len(train))\n",
    "oof_m2 = np.zeros(len(train))\n",
    "pred_m1 = np.zeros(len(test))\n",
    "pred_m2 = np.zeros(len(test))\n",
    "\n",
    "fold_mae_m1 = []\n",
    "fold_mae_m2 = []\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y[trn_idx], y[val_idx]\n",
    "\n",
    "    # Model 1: HistGradientBoostingRegressor (fast + good baseline)\n",
    "    m1 = HistGradientBoostingRegressor(random_state=RANDOM_SEED)\n",
    "    m1.fit(X_tr, y_tr)\n",
    "    p1_val = m1.predict(X_val)\n",
    "    p1_test = m1.predict(X_test)\n",
    "    oof_m1[val_idx] = p1_val\n",
    "    pred_m1 += p1_test / N_SPLITS\n",
    "    mae1 = MAE(y_val, p1_val)\n",
    "    fold_mae_m1.append(mae1)\n",
    "    if VERBOSE: print(f\"[M1] Fold {fold} MAE = {mae1:.6f}\")\n",
    "\n",
    "    # Model 2: RandomForestRegressor (very basic)\n",
    "    m2 = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    m2.fit(X_tr, y_tr)\n",
    "    p2_val = m2.predict(X_val)\n",
    "    p2_test = m2.predict(X_test)\n",
    "    oof_m2[val_idx] = p2_val\n",
    "    pred_m2 += p2_test / N_SPLITS\n",
    "    mae2 = MAE(y_val, p2_val)\n",
    "    fold_mae_m2.append(mae2)\n",
    "    if VERBOSE: print(f\"[M2] Fold {fold} MAE = {mae2:.6f}\")\n",
    "\n",
    "# Print CV summaries\n",
    "print(\"\\nSummary:\")\n",
    "print(f\" Model 1 CV mae: {np.mean(fold_mae_m1):.6f} ± {np.std(fold_mae_m1):.6f}\")\n",
    "print(f\" Model 2 CV mae: {np.mean(fold_mae_m2):.6f} ± {np.std(fold_mae_m2):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6763385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T06:24:08.930077Z",
     "iopub.status.busy": "2025-11-02T06:24:08.929494Z",
     "iopub.status.idle": "2025-11-02T06:24:09.003102Z",
     "shell.execute_reply": "2025-11-02T06:24:09.002191Z"
    },
    "papermill": {
     "duration": 0.078986,
     "end_time": "2025-11-02T06:24:09.004487",
     "exception": false,
     "start_time": "2025-11-02T06:24:08.925501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best blend alpha (M1 weight): 0.850 | CV mae = 0.043656\n"
     ]
    }
   ],
   "source": [
    "# ========= Simple blend (alpha for Model1 vs Model2) =========\n",
    "# We search alpha in [0,1] step 0.05 to minimize OOF MAE.\n",
    "alphas = np.linspace(0,1,21)\n",
    "best_alpha = None\n",
    "best_mae = 1e9\n",
    "for a in alphas:\n",
    "    blend = a*oof_m1 + (1-a)*oof_m2\n",
    "    m = MAE(train[TARGET_COL].values, blend)\n",
    "    if m < best_mae:\n",
    "        best_mae = m\n",
    "        best_alpha = a\n",
    "\n",
    "print(f\"Best blend alpha (M1 weight): {best_alpha:.3f} | CV mae = {best_mae:.6f}\")\n",
    "\n",
    "# Blended test predictions\n",
    "pred_blend = best_alpha*pred_m1 + (1-best_alpha)*pred_m2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054ff09",
   "metadata": {
    "papermill": {
     "duration": 0.002959,
     "end_time": "2025-11-02T06:24:09.010912",
     "exception": false,
     "start_time": "2025-11-02T06:24:09.007953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Evaluation & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a930bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T06:24:09.017745Z",
     "iopub.status.busy": "2025-11-02T06:24:09.017519Z",
     "iopub.status.idle": "2025-11-02T06:24:23.529455Z",
     "shell.execute_reply": "2025-11-02T06:24:23.528783Z"
    },
    "papermill": {
     "duration": 14.516822,
     "end_time": "2025-11-02T06:24:23.530841",
     "exception": false,
     "start_time": "2025-11-02T06:24:09.014019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF RMSE: 0.05621490984560047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X = train[features].values\n",
    "y = train[TARGET_COL].values\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(len(train))\n",
    "\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    X_tr, X_val = X[tr_idx], X[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "    \n",
    "    model = HistGradientBoostingRegressor(random_state=42)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    preds = model.predict(X_val)\n",
    "    \n",
    "    oof_preds[val_idx] = preds\n",
    "\n",
    "# final RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, oof_preds))\n",
    "print(\"OOF RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a8d27",
   "metadata": {
    "papermill": {
     "duration": 0.002983,
     "end_time": "2025-11-02T06:24:23.537626",
     "exception": false,
     "start_time": "2025-11-02T06:24:23.534643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b509e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T06:24:23.545563Z",
     "iopub.status.busy": "2025-11-02T06:24:23.544772Z",
     "iopub.status.idle": "2025-11-02T06:24:23.560168Z",
     "shell.execute_reply": "2025-11-02T06:24:23.559533Z"
    },
    "papermill": {
     "duration": 0.020467,
     "end_time": "2025-11-02T06:24:23.561268",
     "exception": false,
     "start_time": "2025-11-02T06:24:23.540801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen strategy = blend\n"
     ]
    }
   ],
   "source": [
    "# ========= Choose the final strategy =========\n",
    "cv1 = np.mean(fold_mae_m1)\n",
    "cv2 = np.mean(fold_mae_m2)\n",
    "best_cv = min(cv1, cv2, best_mae)\n",
    "\n",
    "if best_cv == best_mae:\n",
    "    strategy = \"blend\"\n",
    "    final_pred = pred_blend\n",
    "elif best_cv == cv1:\n",
    "    strategy = \"m1\"\n",
    "    final_pred = pred_m1\n",
    "else:\n",
    "    strategy = \"m2\"\n",
    "    final_pred = pred_m2\n",
    "\n",
    "print(f\"Chosen strategy = {strategy}\")\n",
    "\n",
    "# ========= Build submission =========\n",
    "sub = pd.DataFrame({\n",
    "    ID_COL: test[ID_COL].values if ID_COL in test.columns else np.arange(len(test)),\n",
    "    TARGET_COL: final_pred\n",
    "})\n",
    "\n",
    "# Sort by ID to be nice (if ID is sortable)\n",
    "try:\n",
    "    sub = sub.sort_values(by=ID_COL)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fee7757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T06:24:23.568861Z",
     "iopub.status.busy": "2025-11-02T06:24:23.568655Z",
     "iopub.status.idle": "2025-11-02T06:24:23.920974Z",
     "shell.execute_reply": "2025-11-02T06:24:23.920140Z"
    },
    "papermill": {
     "duration": 0.357598,
     "end_time": "2025-11-02T06:24:23.922421",
     "exception": false,
     "start_time": "2025-11-02T06:24:23.564823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission.csv\n",
      "       id  accident_risk\n",
      "0  517754       0.293230\n",
      "1  517755       0.123844\n",
      "2  517756       0.185887\n",
      "3  517757       0.322008\n",
      "4  517758       0.411022\n"
     ]
    }
   ],
   "source": [
    "sub_path = \"submission.csv\"\n",
    "sub.to_csv(sub_path, index=False)\n",
    "print(f\"Saved: {sub_path}\")\n",
    "print(sub.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148938f7",
   "metadata": {
    "papermill": {
     "duration": 0.003237,
     "end_time": "2025-11-02T06:24:23.929617",
     "exception": false,
     "start_time": "2025-11-02T06:24:23.926380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The experiments demonstrate that tree-based ensemble models, such as HistGradientBoosting and RandomForest, can effectively capture complex interactions in the dataset and provide solid predictive performance for accident risk estimation.\n",
    "\n",
    "Key takeaways include:\n",
    "\n",
    "* Gradient boosting achieved the most stable MAE scores across folds.\n",
    "\n",
    "* Feature encoding and proper handling of categorical data significantly impact model performance.\n",
    "\n",
    "* Cross-validation proved essential for reliable model comparison and generalization.\n",
    "\n",
    "Future improvements may focus on:\n",
    "\n",
    "* Incorporating spatial and temporal features (e.g., weather, traffic density, road type).\n",
    "\n",
    "* Trying advanced ensemble techniques (e.g., LightGBM, CatBoost, or stacking).\n",
    "\n",
    "* Conducting feature importance analysis to better understand the key accident risk drivers.\n",
    "\n",
    "This notebook provides a solid foundation for further exploration and benchmarking in road accident prediction tasks."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13760552,
     "sourceId": 91721,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1183.493377,
   "end_time": "2025-11-02T06:24:25.454779",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-02T06:04:41.961402",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
